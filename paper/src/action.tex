We want to estimate the posterior probability distribution over actions
conditioned on the current traffic situation and segment. To this end, we
closely follow the strategy of Section~\ref{sec:labeling}. To each of the
traffic situation model $M_i$ is associated an action model $A_i$, which we fit
with a Gaussian Mixture Model (GMM). For the same traffic situation $M_i$, we
are able to model several possible behaviors corresponding to the different
Gaussian components. For instance, when we reach a traffic light, we might brake
when the light is red and continue when it is green. Moreover, a driver does not
always brake or accelerate exactly the same manner every time. Finally, our
system can adapt to new drivers. We can thus formulate the following model that
we estimate and update at each time step:

\begin{equation}
\label{eqn:action}
p(\mathbf{a_t} \mid r_t, l_t,\mathbf{z}_{1:t},\boldsymbol{\psi}^{\mathbf{x}_t})=
\sum_{\mathbf{x}_t} p(\mathbf{x}_t)p(\mathbf{a}_t\mid\mathbf{x}_t,r_t,l_t,
\mathbf{z}_{1:t},\boldsymbol{\psi}^{\mathbf{x}_t}),
\end{equation}

where $\mathbf{x}_t$ is a $K$-dimensional vector with a single one at the
position $k$ encoding for the $k$-th Gaussian and zeros elsewhere,
$p(\mathbf{x}_t)$ is the prior for selecting a particular Gaussian component
$\mathbf{x}_t$, and $p(\mathbf{a}_t\mid\mathbf{x}_t,r_t,l_t,
\mathbf{z}_{1:t},\boldsymbol{\psi}^{\mathbf{x}_t})$ is a Gaussian distribution
with hyperparameters $\boldsymbol{\psi}^{\mathbf{x}_t}$. In a similar fashion as
in Section~\ref{sec:motion}, we have marginalized out the parameters of the
Gaussian and we are thus able to iteratively update the hyperparameters. The
prior distribution $p(\mathbf{x}_t)$ is defined as

\begin{equation}
\label{eqn:gaussianprior}
p(\mathbf{x}_t(i)=1)\propto n_t^i,
\end{equation}

where $n_t^i$ is the sum of the points assigned to Gaussian component $i$.

Upon reception of a new data point $\mathbf{z}_t$, we perform the likelihood
ratio test on all the Gaussian components $\mathbf{x}_{t-1}$ of the model $l_t$.
Compared to the method proposed in Section~\ref{sec:labeling}, the Chi-square
assumption does not hold and we directly threshold the ratio with $\varepsilon$.
If all the components are rejected, a new Gaussian is created with
hyperparameters $\boldsymbol{\psi}_0$. We update the hyperparameters of the most
likely Gaussian component with the rule from \eqref{eqn:hyperupdate} and
increment the corresponding $n_t^i$.

From an implementation point of view, the distribution~\eqref{eqn:action} and
the learned GMM $A_i$ are attached to the particle filter of
Section~\ref{sec:motion}.
