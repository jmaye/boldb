Given a vehicle equipped with an Inertial Measurement Unit (IMU) and a monocular
camera, we seek to learn the relation between motion and visual data in an
on-line and unsupervised manner. We shall follow an entirely probabilistic
approach and formulate the problem as the estimation of the joint filtering
distribution

\begin{equation}
\label{eqn:jointfiletering}
p(r_t,l_t,\mathbf{a}_t\mid\mathbf{z}_{1:t},\mathbf{c}_{1:t}),
\end{equation}

where $r_t$ represents the motion segment length at time $t$, $l_t$ the image
label at time $t$, $\mathbf{a}_t$ the predicted action at time $t$,
$\mathbf{z}_{1:t}$ the IMU measurements up to time $t$, and $\mathbf{c}_{1:t}$
the camera measurements up to time $t$.

Exploiting conditional independences in \eqref{eqn:jointfiletering} provides the
decomposition

\begin{equation}
\label{eqn:jointdecomposition}
p(r_t,l_t,\mathbf{a}_t\mid\mathbf{z}_{1:t},\mathbf{c}_{1:t})=
p(r_t\mid\mathbf{z}_{1:t})p(l_t\mid r_t,\mathbf{c}_{1:t})
p(\mathbf{a}_t\mid r_t,l_t).
\end{equation}

$p(r_t\mid\mathbf{z}_{1:t})$ corresponds to the motion segmentation of
Section~\ref{sec:motion}, $p(l_t\mid r_t,\mathbf{c}_{1:t})$ to the traffic situation
modeling of Section~\ref{sec:labeling}, and $p(\mathbf{a}_t\mid r_t,l_t)$ to the action
prediction model of Section~\ref{sec:action}.
