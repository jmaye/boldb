One research area that has turned more and more into the focus of interest
during the last years is the development of driver intelligent assistant
systems. In particular, a very active topic is the design of human-friendly
vehicle control systems, able to meet the driver specific behaviors. In this
paper we address the problem of learning driver behaviors by using multiple
sensing modalities, namely camera images and inertial information (IMU). Most
existing techniques build a behavior model from heuristic rules or from
supervised training data. Our approach proposes a novel Bayesian on-line and
unsupervised way of learning driver's behavior in different traffic conditions.
Specifically we learn the relationship between vehicle motion and image streams.

Motion data is segmented by using a \textit{change-point} detection method, a
technique that solves the problem of detecting abrupt changes to the parameters
of a statistical model. We use a Bayesian approach to compute the probability of
a change-point occurring at each time step. We have formulated a fast
approximation of this method by using a Rao-Blackwellized particle filter.
The motion segments are grouped together to represent traffic situations by
exploiting similarity in the associated image streams. This is computed on-line
and in an unsupervised manner. The streams are represented as collection of
bag-of-words modeled after a Dirichlet Compound Multinomial model. This process
provides tools to predict the driving actions conditioned on the current traffic
situation.

The the paper is structured as follows. Section~\ref{sec:related}
summarizes the previous work related to ours. Section~\ref{sec:motion}
describes our motion segmentation method. Section~\ref{sec:labeling}
shows how we model a traffic situation. Section~\ref{sec:action} demonstrates
our action model. Section~\ref{sec:exp} presents experimental results.
Section~\ref{sec:conc} outlines our conclusions and provides some insights for
future work.
